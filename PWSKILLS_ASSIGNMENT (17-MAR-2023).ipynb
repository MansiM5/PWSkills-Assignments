{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4ee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some\n",
    "algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bebcf",
   "metadata": {},
   "source": [
    "Missing values in a dataset is when one or more data point is missing in a variable or two. It is essential to handle missing values to prevent poor performance of a model due to biased or incorrect results.\n",
    "Decision Tree, KNN, Random Forest, Naive Bayes, SVM are algorithms that are not affected by missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea384bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa48cea",
   "metadata": {},
   "source": [
    "Techniques used to handle missing data\n",
    "* Dropping the rows or feature(incase not relevant to ouput)\n",
    "* Replacing NaN with Mean\n",
    "* Replacing NaN with Median\n",
    "* Replacing NaN with Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c987d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset(\"penguins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37c683a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species               0\n",
       "island                0\n",
       "bill_length_mm        2\n",
       "bill_depth_mm         2\n",
       "flipper_length_mm     2\n",
       "body_mass_g           2\n",
       "sex                  11\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1c8747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bill_length_mm']=df['bill_length_mm'].fillna(df['bill_length_mm'].mean())\n",
    "df['bill_depth_mm']=df['bill_depth_mm'].fillna(df['bill_depth_mm'].median())\n",
    "df['flipper_length_mm']=df['flipper_length_mm'].fillna(df['flipper_length_mm'].median())\n",
    "df['body_mass_g']=df['body_mass_g'].fillna(df['body_mass_g'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de5941",
   "metadata": {},
   "source": [
    "#### We can use mode for categorical values, since here Sex is categorical feature and has null values, and we cannot define Sex on the basis of mode. If we had to use, we can do it by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ea4d737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female', nan], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].unique()\n",
    "mode_val= df[df['sex'].notna()]['sex'].mode()[0]\n",
    "df['sex']=df['sex'].fillna(mode_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57002d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species              0\n",
       "island               0\n",
       "bill_length_mm       0\n",
       "bill_depth_mm        0\n",
       "flipper_length_mm    0\n",
       "body_mass_g          0\n",
       "sex                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbde068",
   "metadata": {},
   "source": [
    "Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8282da",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a situation wherein distribution of classes or target variables in dataset is not balanced. Example- In a survery, we might get more \"yes\" for an answer than \"no\", and if we train our model according to this, our model will be biased towards \"yes\". \n",
    "\n",
    "If imbalanced data is not handled, it can lead to bias and incorrect model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-\n",
    "sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9115c",
   "metadata": {},
   "source": [
    "Up-sampling and Down-sampling are two techniques for handling imbalanced data in a daatset. \n",
    "Up-sampling: we try to increase data points from minority variable\n",
    "Down-sampling: we try to decrease data points from majority variable\n",
    "\n",
    "Example: Suppose you are working on a credit card fraud detection problem where the positive class represents fraudulent transactions and the negative class represents legitimate transactions. Suppose only 1% of transactions are fraudulent. The model may be biased towards the negative class. If the model is trained on this imbalanced dataset, it may perform poorly on the minority class, leading to higher false negative rates. Up-sampling the minority class would involve creating new fraudulent transactions based on existing ones until the number of fraudulent transactions is equal to the number of legitimate transactions. Down-sampling the majority class would involve randomly removing some legitimate transactions until the number of fraudulent transactions is equal to the number of legitimate transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974bbb8",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used in machine learning to increase the size of a dataset by creating additional, synthetic data based on the existing data. \n",
    "\n",
    "SMOTE (Synthetic Minority Oversampling Techniques) is used to address imbalanced datasets where minority class has significantly few instances than majority class. It involves generating synthetic instances of minority class by interpolating between exisiting instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8bf3e",
   "metadata": {},
   "source": [
    "Outliers are observation or a data point which is different from other observation/data points in a dataset.\n",
    "\n",
    "It is essential to handle outliers as they hinder statistical analysis, like skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: You are working on a project that requires analyzing customer data. However, you notice that some of\n",
    "the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5a8160",
   "metadata": {},
   "source": [
    "Techniques to handle the missing data in analysis:\n",
    "1. Drop the certain row or a feature if it does not significantly contribute towards predictions\n",
    "2. Replace missing values with the Mean of that feature\n",
    "3. Replace missing values with the Median of that feature\n",
    "4. Replace missing values with the Mode of that feature- incase of categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0646abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are\n",
    "some strategies you can use to determine if the missing data is missing at random or if there is a pattern\n",
    "to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712397a9",
   "metadata": {},
   "source": [
    "Descriptive analysis: You can start by looking at the descriptive statistics of the variables with missing data and compare them with the ones that have complete data. If the missing data is not related to any of the variables or the sample characteristics, it is likely to be missing at random. On the other hand, if there is a difference between the descriptive statistics of the two groups, it may indicate that there is a pattern to the missing data.\n",
    "\n",
    "Correlation analysis: You can also look at the correlations between the variables with missing data and the ones that have complete data. If the missing data is not related to any of the other variables, it is likely to be missing at random. However, if there is a significant correlation between the missing data and any of the other variables, it may suggest that there is a pattern to the missing data.\n",
    "\n",
    "Missingness patterns: You can also examine the patterns of missing data across the variables in the dataset. For example, if the missing data tends to occur more frequently in certain subgroups of the data, such as specific age groups or geographic regions, it may suggest that there is a pattern to the missing data.\n",
    "\n",
    "Imputation and analysis: Finally, you can try imputing the missing data using different techniques and compare the results. If the results are consistent across different imputation methods, it may suggest that the missing data is missing at random. However, if the results vary significantly depending on the imputation method used, it may indicate that there is a pattern to the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69465fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the\n",
    "dataset do not have the condition of interest, while a small percentage do. What are some strategies you\n",
    "can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0060c88d",
   "metadata": {},
   "source": [
    "* Confusion matrix\n",
    "\n",
    "* Resampling techniques\n",
    "\n",
    "* Threshold tuning\n",
    "\n",
    "* Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is\n",
    "unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to\n",
    "balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41feb0d7",
   "metadata": {},
   "source": [
    "* Random under-sampling\n",
    "* Cluster-based under-sampling\n",
    "\n",
    "* Tomek links\n",
    "\n",
    "* Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "\n",
    "* Ensemble techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f10d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a\n",
    "project that requires you to estimate the occurrence of a rare event. What methods can you employ to\n",
    "balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c36a109",
   "metadata": {},
   "source": [
    "* Random over-sampling\n",
    "\n",
    "* Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "\n",
    "* Adaptive Synthetic Sampling \n",
    "\n",
    "* Ensemble techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030e386",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
